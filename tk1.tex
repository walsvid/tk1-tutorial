% Encoding: UTF8
% \documentclass{ctexart}

\documentclass[openany]{ctexbook}
\usepackage{graphicx}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[mathscr]{eucal}
\usepackage{pythonhighlight}
\usepackage{fancyhdr}
\usepackage{textcomp}
\usepackage[top=1in,bottom=1in, left=1in, right=1in]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}
\lstset{
    columns=fixed,
    numbers=left,                                        % 在左侧显示行号
    frame=none,                                          % 不显示背景边框
    backgroundcolor=\color[RGB]{245,245,244},            % 设定背景颜色
    keywordstyle=\color[RGB]{40,40,255},                 % 设定关键字颜色
    numberstyle=\footnotesize\color{darkgray},           % 设定行号格式
    commentstyle=\it\color[RGB]{0,96,96},                % 设置代码注释的格式
    stringstyle=\rmfamily\slshape\color[RGB]{128,0,0},   % 设置字符串格式
    showstringspaces=false,                                       % 设置语言
}

\newcommand{\warn}[1] {\fcolorbox{red!20}{red!20} {\color{red} #1}}
\newcommand{\info}[1] {\fcolorbox{blue!20}{blue!20} {\color{blue} #1}}


\begin{document}

\begin{titlepage}
  \pagenumbering{roman}
  \title{NVIDIA Jetson TK1使用介绍文档}
  \author{闻超\\v0.1.0}
  \date{\today}
  \maketitle
  \setcounter{page}{1}
  \tableofcontents
\end{titlepage}

\pagenumbering{arabic}
\chapter{NVIDIA Jetson TK1介绍}
\section{硬件参数介绍}
\paragraph{尺寸}
127mm x 127mm
\paragraph{TK1 SOC}
CPU+GPU+ISP一体设计
\paragraph{GPU}
NVIDIA Kepler ``GK20a'' GPU with 192 SM3.2 CUDA cores (upto 326 GFLOPS)
\paragraph{CPU}
NVIDIA 2.32GHz ARM quad-core Cortex-A15 CPU
\paragraph{DRAM}
2GB DDR3L 933MHz EMC x16 使用 64-bit 数据位宽
\paragraph{存储}
16GB fast eMMC 4.51
\paragraph{mini-PCIe}
此接口可用于SSD、WiFi、以太网的扩展

\begin{figure}[h]
  \centering
  \includegraphics[width=5.5in]{1.jpg}
  \caption{TK1硬件组件介绍}
\end{figure}

\section{入门资料汇总}
对于第一次使用TK1的童鞋们，可以仔细阅读以下网址提供的资料：\url{http://elinux.org/Jetson_TK1}

TK1开发板的一些资料下载网址：\url{https://developer.nvidia.com/jetson-tk1}

入门视频教学：\url{http://www.iqiyi.com/a_19rrhc0aql.html}

\section{接口相关注意事项}
\begin{enumerate}
  \item Jetson TK1只提供一个USB接口，因此若想连接鼠标、键盘等外设，可以自己购买一个USB-HUB来使用
  \item Jetson TK1提供的显示接口是HDMI，如果没有HDMI接口显示器，可以买一个HDMI转VGA或者DVI接口线即可
\end{enumerate}

\section{Jetson TK1 支持的实验框架}
TK1支持许多常见的Machine Learning、Computer Vision框架。详细列表可见\url{http://elinux.org/Jetson_TK1#Tutorials_for_developing_with_Jetson_TK1}
同时，近些年深度学习多种框架出现，TK1也在不同程度上支持这些框架，这些在上面的网址中可能没有详细说明，具体请见本文档后续的内容。


\chapter{开箱与GUI系统安装}
\section{开箱使用}
首先，连接好电源和显示器、鼠标等外设之后，按电源键进入命令行界面进行带GUI的系统的安装过程。
也就是Linux的Ubuntu发行版。可以看到，屏幕上有相关提示：
\begin{figure}[h]
  \centering
  \includegraphics[width=5.5in]{2.jpg}
  \caption{第一次使用时的命令行界面}
\end{figure}

进入安装目录
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
cd NVIDIA-INSTALLER
\end{lstlisting}}
运行安装脚本
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
sudo ./installer.sh
\end{lstlisting}}
按提示输入密码，都是\warn{ubuntu}

安装完成之后，重启机器
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
sudo reboot
\end{lstlisting}}

至此，开箱的第一步工作已经完成，可以看到，现在已经可以进入Ubuntu系统了。
\begin{figure}[h]
  \centering
  \includegraphics[width=5.5in]{3.jpg}
  \caption{Ubuntu系统桌面}
\end{figure}

\section{配置远程连接}
暂未完成



\chapter{CUDA的安装}
\section{下载并安装CUDA包}
Jetson TK1支持NVIDIA CUDA，不过暂时仍旧只对低版本支持较好，高版本的支持情况可以等待本文档的后续更新。
下载安装包：\url{https://developer.nvidia.com/cuda-toolkit-60}
如图所示，应该选择对应的CUDA版本，由于TK的出厂时间较早，支持的比较好的版本是6.0，而且要选择\warn{Linux for Tegra}这个版本。
\begin{figure}[h]
  \centering
  \includegraphics[width=5.5in]{4.png}
  \caption{CUDA6release界面}
\end{figure}

下载后可以见到deb包
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
ls
cuda-repo-l4t-r19.2_6.0-42_armhf.deb
\end{lstlisting}}

安装deb包
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
sudo apt-get update
sudo dpkg -i xxx.deb
\end{lstlisting}}

安装samples和toolkit
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
sudo apt-get install cuda-samples-6-0
sudo apt-get install cuda-toolkit-6-0
\end{lstlisting}}

设置当前用户下可以访问GPU
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
sudo usermod -a -G video ubuntu
\end{lstlisting}}

\warn{修改环境变量}
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
vim ~/.bashrc
\end{lstlisting}}

在后面加上
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
# Add CUDA bin and lib path
export PATH=/usr/local/cuda-6.0/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-6.0/lib:$LD_LIBRARY_PATH
\end{lstlisting}}

更新bashrc
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
source .bashrc
\end{lstlisting}}

检查是否安装正常
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
nvcc -V
\end{lstlisting}}
如图所示即为安装完成。

\begin{figure}[h]
  \centering
  \includegraphics[width=4in]{5.png}
  \caption{CUDA安装完成}
\end{figure}

\pagebreak
\section{编译与运行例程}
进入cuda目录并查看当前目录中是否有samples
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
cd /usr/local/cuda
ls
\end{lstlisting}}
\begin{figure}[h]
  \centering
  \includegraphics[width=6in]{6.png}
  \caption{目录文件}
\end{figure}
将samples拷贝到所需要的目录
\info{cuda-install-samples-6.0.sh}是bin下面的文件，应该已经添加到PATH环境变量，不需要绝对路径即可运行，如果不能运行，请检查是否添加了环境变量。
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
cuda-install-samples-6.0.sh /home/ubuntu/
\end{lstlisting}}
回到主目录下查看
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
cd
ls
\end{lstlisting}}
如果有名为
\info{NVIDIA\_CUDA-6.0\_Samples}
的文件夹拷贝samples就完成了。
下面我们编译CUDA的samples
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
cd NVIDIA_CUDA-6.0_Samples
make
\end{lstlisting}}
编译完成之后我们可以在
{\setmainfont{Courier New Bold} ./bin/armv7l/linux/release/gnueabihf}
找到编译好的文件

一下是运行某些例程的截图，可以自行探索。

\begin{figure*}[h]
    \centering
        \begin{subfigure}[h!]{0.5\textwidth}
            \centering
            \includegraphics[height=1.8in]{8.png}
            \caption{sample截图1}
        \end{subfigure}%
        ~
        \begin{subfigure}[h!]{0.5\textwidth}
            \centering
            \includegraphics[height=1.8in]{9.png}
            \caption{sample截图2}
        \end{subfigure}
        \caption{例程截图}
\end{figure*}

\chapter{安装OpenCV}
\section{OpenCV下载}
首先注册NVIDIA的开发者账号\url{https://developer.nvidia.com}

下载OpenCV，下载地址：\url{https://developer.nvidia.com/linux-tegra-rel-19}

选择如下两个安装包，下载
\begin{figure}[h]
  \centering
  \includegraphics[width=6in]{10.png}
  \caption{OpenCV TK1所需优化包}
\end{figure}

下载OpenCV源码，此处下载的版本虽然不是2.4.8但是仍可以编译通过，建议尽量选择与之匹配的版本，2.4.9即可。
直接从下面的网址下载即可，如果速度较慢建议通过带有VPN的机器下载完成后拷贝到TK1中。

可以点此下载：
\href{http://downloads.sourceforge.net/project/opencvlibrary/opencv-unix/2.4.9/opencv-2.4.9.zip}{OpenCV2.4.9下载}

也可以选择如下的命令行方式：
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
wget http://downloads.sourceforge.net/project/opencvlibrary/\
opencv-unix/2.4.9/opencv-2.4.9.zip
\end{lstlisting}}

完成后可以看到如下的文件，表明下载完成
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
libopencv4tegra_2.4.8.2_armhf.deb
libopencv4tegra-dev_2.4.8.2_armhf.deb
opencv-2.4.9.zip
\end{lstlisting}}

\section{安装OpenCV依赖}
首先更新源，并且安装OpenCV的若干依赖库。需要注意的是，这些库并非必须，全部安装可以支持较多格式，请根据需要进行安装。
必须安装的用MUST标出。
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
sudo apt-get update
# MUST Some general development libraries
sudo apt-get install build-essential -y
sudo apt-get install make cmake cmake-curses-gui g++ git  -y
# MUST Required libraries
sudo apt-get install libgtk2.0-dev pkg-config -y
sudo apt-get libavcodec-dev libavformat-dev libswscale-dev  -y
# Python libraries
sudo apt-get install python-dev python-numpy -y
# Other dependent libraries
sudo apt-get libavutil-dev libv4l-dev libeigen3-dev -y
sudo apt-get libglew1.6-dev libtbb2 libtbb-dev libjpeg-dev -y
sudo apt-get libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev -y
\end{lstlisting}}

接下来安装之前下载的两个deb包
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
sudo dpkg -i libopencv4tegra_2.4.8.2_armhf.deb
sudo dpkg -i libopencv4tegra-dev_2.4.8.2_armhf.deb
\end{lstlisting}}

\section{源码编译OpenCV}
首先解压缩OpenCV的源代码，然后建立编译需要的build目录。
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
unzip opencv-2.4.9.zip
cd ~/opencv-2.4.9
mkdir build
cd build
\end{lstlisting}}
接下来我们可以查看cmake的编译选项：
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
ccmake ..
\end{lstlisting}}
需要注意的是，查看是否有CUDA支持，是否有Python支持。
\begin{figure}[h]
  \centering
  \includegraphics[width=5.5in]{11.png}
  \caption{ccmake编译选项的可视化显示}
\end{figure}

编译并安装OpenCV
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
sudo make -j4
sudo make install
\end{lstlisting}}

若能如图所示，表示OpenCV的Python支持安装成功。
\begin{figure}[h]
  \centering
  \includegraphics[width=5.5in]{12.png}
  \caption{Python显示OpenCV版本}
\end{figure}

如果想测试GPU支持，可以到如下目录运行samples
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
cd ~/opencv-2.4.9/samples/gpu
./hog --video 768x576.avi
\end{lstlisting}}

至此，OpenCV安装成功！

\chapter{YOLO Draknet编译}
\section{编译安装Darknet}
首先拉取repo，然后进行编译

\warn{此处的编译仅针对CPU版本，支持CUDA的GPU编译方式注意下一小节内容}
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
git clone https://github.com/pjreddie/darknet.git
cd darknet
make
\end{lstlisting}}
等待编译完成之后尝试运行
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
./darknet
\end{lstlisting}}
应该得到如下的输出
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
usage: ./darknet <function>
\end{lstlisting}}
至此，YOLO Darknet编译安装完成。
\section{支持CUDA的编译}
尽管YOLO Darknet已经有较快的物体检测速度，但是使用GPU可以得到数十倍甚至近百倍的速度加成，下面介绍如何在编译时支持CUDA。
需要修改Makefile文件，有以下几点需要注意。

将原来的Makefile
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=make]
GPU=0
...
OPENCV=0
...
ARCH= -gencode arch=compute_20,code=[sm_20,sm_21] \
      -gencode arch=compute_30,code=sm_30 \
      -gencode arch=compute_35,code=sm_35 \
      -gencode arch=compute_50,code=[sm_50,compute_50] \
      -gencode arch=compute_52,code=[sm_52,compute_52]
...
LDFLAGS+= -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand
\end{lstlisting}}
改为支持CUDA的编译选项
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=make]
GPU=1
...
OPENCV=1
...
ARCH=  -gencode arch=compute_20,code=compute_20
...
LDFLAGS+= -L/usr/local/cuda/lib -lcuda -lcudart -lcublas -lcurand
\end{lstlisting}}

\section{测试安装结果}
测试一下GPU的支持以及OpenCV的支持
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
# Test OpenCV
./darknet imtest data/eagle.jpg
# Test GPU
wget http://pjreddie.com/media/files/yolo.weights
./darknet -i 0 detect cfg/yolo.cfg yolo.weights data/dog.jpg
\end{lstlisting}}

如下图可以认为Draknet也安装成功。

\begin{figure*}[h]
    \centering
        \begin{subfigure}[h!]{0.5\textwidth}
            \centering
            \includegraphics[height=1.8in]{13.png}
            \caption{Darknet OpenCV测试}
        \end{subfigure}%
        ~
        \begin{subfigure}[h!]{0.5\textwidth}
            \centering
            \includegraphics[height=1.8in]{14.png}
            \caption{Darknet GPU测试}
        \end{subfigure}
        \caption{Darknet运行结果截图}
\end{figure*}

\chapter{NVIDIA tk1 实际工程项目实践}
\section{使用YOLO并结合摄像头实现image/video object detection}
YOLO算法使用的darknet模型框架只依赖CUDA，可以直接在tk1上运行。
对于网络权重的训练部分在服务器端进行，tk1上直接进行测试。
对于源码分析一下：
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=c]
void run_yolo(int argc, char **argv)
{
    char *prefix = find_char_arg(argc, argv, "-prefix", 0);
    float thresh = find_float_arg(argc, argv, "-thresh", .2);
    int cam_index = find_int_arg(argc, argv, "-c", 0);
    int frame_skip = find_int_arg(argc, argv, "-s", 0);
    if(argc < 4){
        fprintf(stderr, "usage: %s %s [train/test/valid] \
        [cfg] [weights (optional)]\n", argv[0], argv[1]);
        return;
    }

    char *cfg = argv[3];
    char *weights = (argc > 4) ? argv[4] : 0;
    char *filename = (argc > 5) ? argv[5]: 0;
    if(0==strcmp(argv[2], "test"))
        test_yolo(cfg, weights, filename, thresh);
    else if(0==strcmp(argv[2], "train"))
        train_yolo(cfg, weights);
    else if(0==strcmp(argv[2], "valid"))
        validate_yolo(cfg, weights);
    else if(0==strcmp(argv[2], "recall"))
        validate_yolo_recall(cfg, weights);
    else if(0==strcmp(argv[2], "demo"))
        demo(cfg, weights, thresh, cam_index, \
          filename, voc_names, 20, frame_skip, prefix);
}
\end{lstlisting}}
通过分析上面的代码，在运行YOLO的时候，如果是图片，就应该选择test作为参数；
如果是视频的格式，就选择demo作为视频的参数，并且要注意传入摄像头的编号。
\subsection{yolo模型介绍}
% 这里简单介绍YOLO
\subsubsection{模型思想}
YOLO的核心思想就是利用整张图作为网络的输入，直接在输出层回归bounding box的位置和bounding box所属的类别。

faster RCNN中也直接用整张图作为输入，但是faster-RCNN整体还是采用了RCNN那种 proposal+classifier的思想，只不过是将提取proposal的步骤放在CNN中实现了。

具体采用的实现方法：
将一幅图像分成SxS个网格(grid cell)，如果某个object的中心 落在这个网格中，则这个网格就负责预测这个object。
每个网格要预测B个bounding box，每个bounding box除了要回归自身的位置之外，还要附带预测一个confidence值。
这个confidence代表了所预测的box中含有object的置信度和这个box预测的有多准两重信息，其值是这样计算的：
$$Pr(Object)*IOU^{truth}_{predict}$$
其中如果有object落在一个grid cell里，第一项取1，否则取0。 第二项是预测的bounding box和实际的groundtruth之间的IoU值。

每个bounding box要预测(x, y, w, h)和confidence共5个值，每个网格还要预测一个类别信息，记为C类。则SxS个网格，每个网格要预测B个bounding box还要预测C个categories。输出就是S x S x (5*B+C)的一个tensor。
注意：class信息是针对每个网格的，confidence信息是针对每个bounding box的。

在PASCAL VOC数据集中，图像输入为448x448，取S=7，B=2，一共有20个类别(C=20)。则输出就是7x7x30的一个tensor。

在test的时候，每个网格预测的class信息和bounding box预测的confidence信息相乘，就得到每个bounding box的class-specific confidence score:
$$Pr(Class_i|Object)*Pr(Object)*IOU^{truth}_{predict}=Pr(Class_i)*IOU^{truth}_{predict}$$
等式左边第一项就是每个网格预测的类别信息，第二三项就是每个bounding box预测的confidence。这个乘积即encode了预测的box属于某一类的概率，也有该box准确度的信息。

得到每个box的class-specific confidence score以后，设置阈值，滤掉得分低的boxes，对保留的boxes进行NMS处理，就得到最终的检测结果。
\subsubsection{网络结构}
下面是YOLO算法使用的网络模型的结构：
\begin{figure}[h]
  \centering
  \includegraphics[width=5.5in]{15.png}
  \caption{YOLO的网络结构模型}
\end{figure}
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
layer     filters    size              input                output
    0 conv     32  3 x 3 / 1   416 x 416 x   3   ->   416 x 416 x  32
    1 max          2 x 2 / 2   416 x 416 x  32   ->   208 x 208 x  32
    2 conv     64  3 x 3 / 1   208 x 208 x  32   ->   208 x 208 x  64
    3 max          2 x 2 / 2   208 x 208 x  64   ->   104 x 104 x  64
    4 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128
    5 conv     64  1 x 1 / 1   104 x 104 x 128   ->   104 x 104 x  64
    6 conv    128  3 x 3 / 1   104 x 104 x  64   ->   104 x 104 x 128
    7 max          2 x 2 / 2   104 x 104 x 128   ->    52 x  52 x 128
    8 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256
    9 conv    128  1 x 1 / 1    52 x  52 x 256   ->    52 x  52 x 128
   10 conv    256  3 x 3 / 1    52 x  52 x 128   ->    52 x  52 x 256
   11 max          2 x 2 / 2    52 x  52 x 256   ->    26 x  26 x 256
   12 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512
   13 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256
   14 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512
   15 conv    256  1 x 1 / 1    26 x  26 x 512   ->    26 x  26 x 256
   16 conv    512  3 x 3 / 1    26 x  26 x 256   ->    26 x  26 x 512
   17 max          2 x 2 / 2    26 x  26 x 512   ->    13 x  13 x 512
   18 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024
   19 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512
   20 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024
   21 conv    512  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 512
   22 conv   1024  3 x 3 / 1    13 x  13 x 512   ->    13 x  13 x1024
   23 conv   1024  3 x 3 / 1    13 x  13 x1024   ->    13 x  13 x1024
   24 conv   1024  3 x 3 / 1    13 x  13 x1024   ->    13 x  13 x1024
   25 route  16
   26 reorg              / 2    26 x  26 x 512   ->    13 x  13 x2048
   27 route  26 24
   28 conv   1024  3 x 3 / 1    13 x  13 x3072   ->    13 x  13 x1024
   29 conv    425  1 x 1 / 1    13 x  13 x1024   ->    13 x  13 x 425
   30 detection
\end{lstlisting}}
\subsection{可选的tiny-yolo模型}
由于YOLO模型相对于tk1的计算能力来说还是比较庞大，所以可以选用更小但是速度更快的tiny-YOLO来实现video级别的物体检测。
当然这样做的代价是牺牲了准确度。
% 这里展示tiny yolo
\subsection{Image object detection}
对于图片，参数选择是test，调用\info{test\_yolo}
函数。对于图片测试，只需要运行下面的命令即可。
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
./darknet detector test cfg/coco.data cfg/yolo.cfg yolo.weights <image path>
\end{lstlisting}}
\subsection{Video object detection}
对于视频，实时进行object detection，需要调用的是
\info{demo}
函数。需要传入待分析的视频文件或者camera的number。

tk1并不自带摄像头，好在可以使用USB摄像头，无需任何驱动，直接可用。传入的num是0。
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights -c <num>
\end{lstlisting}}
或者可以传入一个视频文件，YOLO会将object detection的结果实时输出。
{\setmainfont{Courier New Bold}                          % 设置代码字体
\begin{lstlisting}[language=bash]
./darknet detector demo cfg/coco.data cfg/yolo.cfg yolo.weights <video file>
\end{lstlisting}}
\section{基于OpenCV和HOG的行人检测}
\section{基于OpenCV的 face detection}



\end{document}
